seed [1995]
devices_type ['1']
2025-11-10 20:17:40,221 [trainer.py] => config: ./exps/sdfourierft_c100.json
2025-11-10 20:17:40,222 [trainer.py] => seed: 1995
2025-11-10 20:17:40,222 [trainer.py] => prefix: reproduce
2025-11-10 20:17:40,222 [trainer.py] => dataset: cifar224
2025-11-10 20:17:40,222 [trainer.py] => memory_size: 0
2025-11-10 20:17:40,222 [trainer.py] => memory_per_class: 0
2025-11-10 20:17:40,222 [trainer.py] => fixed_memory: False
2025-11-10 20:17:40,222 [trainer.py] => shuffle: True
2025-11-10 20:17:40,222 [trainer.py] => init_cls: 10
2025-11-10 20:17:40,222 [trainer.py] => increment: 10
2025-11-10 20:17:40,222 [trainer.py] => model_name: fourierft
2025-11-10 20:17:40,222 [trainer.py] => backbone_type: vit_base_patch16_224
2025-11-10 20:17:40,222 [trainer.py] => device: [device(type='cuda', index=1)]
2025-11-10 20:17:40,222 [trainer.py] => optimizer: adam
2025-11-10 20:17:40,222 [trainer.py] => scheduler: cosine
2025-11-10 20:17:40,222 [trainer.py] => filepath: ./data/CF100
2025-11-10 20:17:40,222 [trainer.py] => init_epoch: 20
2025-11-10 20:17:40,222 [trainer.py] => init_lr: 0.008
2025-11-10 20:17:40,222 [trainer.py] => init_milestones: [60, 120, 170]
2025-11-10 20:17:40,222 [trainer.py] => init_lr_decay: 0.1
2025-11-10 20:17:40,222 [trainer.py] => init_weight_decay: 0.0005
2025-11-10 20:17:40,222 [trainer.py] => epochs: 20
2025-11-10 20:17:40,222 [trainer.py] => lrate: 0.008
2025-11-10 20:17:40,222 [trainer.py] => milestones: [40, 70]
2025-11-10 20:17:40,222 [trainer.py] => lrate_decay: 0
2025-11-10 20:17:40,222 [trainer.py] => batch_size: 128
2025-11-10 20:17:40,222 [trainer.py] => weight_decay: 0.0002
2025-11-10 20:17:40,222 [trainer.py] => fourierft: {'n_frequency': 1000, 'n_frequency_non_trainable': 0, 'scaling': 150.0, 'random_loc_seed': 42, 'init_weights': False, 'prefer': True, 'init_fc': 1, 'fourier_layer': None, 'target_modules': ['q', 'v'], 'bias': 'none', 'modules_to_save': ['classifier'], 'layers_to_transform': None, 'layers_pattern': None, 'n_frequency_pattern': {}, 'fan_in_fan_out': False}
2025-11-10 20:17:40,222 [trainer.py] => indices_file_path: ./results/fourierft_imagenetr
2025-11-10 20:17:40,222 [trainer.py] => reinit_num: 200
2025-11-10 20:17:40,222 [trainer.py] => round_number: 0
2025-11-10 20:17:40,222 [trainer.py] => task_specific_branches: True
2025-11-10 20:17:40,222 [trainer.py] => avoid_index_overlap: True
2025-11-10 20:17:40,222 [trainer.py] => merge_strategy: max
2025-11-10 20:17:40,222 [trainer.py] => merge_adapters: True
2025-11-10 20:17:40,222 [trainer.py] => dynamic_n_frequency: True
Files already downloaded and verified
Files already downloaded and verified
2025-11-10 20:17:41,771 [data_manager.py] => [91, 18, 57, 73, 66, 71, 68, 61, 44, 54, 23, 25, 27, 14, 21, 20, 59, 93, 81, 22, 5, 88, 37, 42, 39, 83, 76, 72, 3, 55, 43, 13, 4, 95, 99, 47, 77, 98, 86, 80, 67, 11, 8, 58, 10, 33, 16, 78, 94, 50, 41, 87, 90, 74, 15, 48, 46, 85, 53, 97, 7, 26, 89, 31, 19, 45, 96, 34, 24, 6, 1, 2, 0, 17, 30, 32, 92, 12, 56, 64, 79, 40, 63, 49, 70, 60, 35, 9, 62, 75, 65, 28, 52, 84, 29, 69, 51, 38, 82, 36]
!!!!!!! multiple_gpus [device(type='cuda', index=1)]
This is for the BaseNet initialization.
2025-11-10 20:17:43,098 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-11-10 20:17:44,001 [_client.py] => HTTP Request: HEAD https://huggingface.co/timm/vit_base_patch16_224.augreg2_in21k_ft_in1k/resolve/main/model.safetensors "HTTP/1.1 302 Found"
2025-11-10 20:17:44,003 [_hub.py] => [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
save_file ./results/fourierft_imagenetr
After BaseNet initialization.
task 0
2025-11-10 20:17:44,725 [sdfourier.py] => Learning on 0-10

  0%|          | 0/20 [00:00<?, ?it/s]
Task 0, Epoch 1/20 => Loss 0.764, Train_accy 75.34, Test_accy 95.60:   0%|          | 0/20 [00:22<?, ?it/s]
Task 0, Epoch 1/20 => Loss 0.764, Train_accy 75.34, Test_accy 95.60:   5%|▌         | 1/20 [00:22<07:07, 22.48s/it]
Task 0, Epoch 2/20 => Loss 0.373, Train_accy 88.42:   5%|▌         | 1/20 [00:42<07:07, 22.48s/it]                 
Task 0, Epoch 2/20 => Loss 0.373, Train_accy 88.42:  10%|█         | 2/20 [00:42<06:21, 21.22s/it]
Task 0, Epoch 3/20 => Loss 0.321, Train_accy 89.82:  10%|█         | 2/20 [01:03<06:21, 21.22s/it]
Task 0, Epoch 3/20 => Loss 0.321, Train_accy 89.82:  15%|█▌        | 3/20 [01:03<05:53, 20.82s/it]
Task 0, Epoch 4/20 => Loss 0.337, Train_accy 89.22:  15%|█▌        | 3/20 [01:23<05:53, 20.82s/it]
Task 0, Epoch 4/20 => Loss 0.337, Train_accy 89.22:  20%|██        | 4/20 [01:23<05:30, 20.66s/it]
Task 0, Epoch 5/20 => Loss 0.332, Train_accy 89.62:  20%|██        | 4/20 [01:44<05:30, 20.66s/it]
Task 0, Epoch 5/20 => Loss 0.332, Train_accy 89.62:  25%|██▌       | 5/20 [01:44<05:08, 20.59s/it]
Task 0, Epoch 6/20 => Loss 0.312, Train_accy 90.18, Test_accy 96.90:  25%|██▌       | 5/20 [02:06<05:08, 20.59s/it]
Task 0, Epoch 6/20 => Loss 0.312, Train_accy 90.18, Test_accy 96.90:  30%|███       | 6/20 [02:06<04:56, 21.21s/it]
Task 0, Epoch 7/20 => Loss 0.321, Train_accy 89.74:  30%|███       | 6/20 [02:26<04:56, 21.21s/it]                 
Task 0, Epoch 7/20 => Loss 0.321, Train_accy 89.74:  35%|███▌      | 7/20 [02:26<04:32, 20.97s/it]
Task 0, Epoch 8/20 => Loss 0.338, Train_accy 89.88:  35%|███▌      | 7/20 [02:47<04:32, 20.97s/it]
Task 0, Epoch 8/20 => Loss 0.338, Train_accy 89.88:  40%|████      | 8/20 [02:47<04:10, 20.85s/it]
Task 0, Epoch 9/20 => Loss 0.291, Train_accy 89.96:  40%|████      | 8/20 [03:07<04:10, 20.85s/it]
Task 0, Epoch 9/20 => Loss 0.291, Train_accy 89.96:  45%|████▌     | 9/20 [03:07<03:47, 20.72s/it]
Task 0, Epoch 10/20 => Loss 0.282, Train_accy 90.76:  45%|████▌     | 9/20 [03:28<03:47, 20.72s/it]
Task 0, Epoch 10/20 => Loss 0.282, Train_accy 90.76:  50%|█████     | 10/20 [03:28<03:26, 20.64s/it]
Task 0, Epoch 11/20 => Loss 0.289, Train_accy 90.80, Test_accy 97.00:  50%|█████     | 10/20 [03:50<03:26, 20.64s/it]
Task 0, Epoch 11/20 => Loss 0.289, Train_accy 90.80, Test_accy 97.00:  55%|█████▌    | 11/20 [03:50<03:11, 21.23s/it]
Task 0, Epoch 12/20 => Loss 0.271, Train_accy 90.98:  55%|█████▌    | 11/20 [04:11<03:11, 21.23s/it]                 
Task 0, Epoch 12/20 => Loss 0.271, Train_accy 90.98:  60%|██████    | 12/20 [04:11<02:47, 20.98s/it]
Task 0, Epoch 13/20 => Loss 0.273, Train_accy 90.80:  60%|██████    | 12/20 [04:31<02:47, 20.98s/it]
Task 0, Epoch 13/20 => Loss 0.273, Train_accy 90.80:  65%|██████▌   | 13/20 [04:31<02:25, 20.82s/it]
Task 0, Epoch 14/20 => Loss 0.245, Train_accy 92.20:  65%|██████▌   | 13/20 [04:52<02:25, 20.82s/it]
Task 0, Epoch 14/20 => Loss 0.245, Train_accy 92.20:  70%|███████   | 14/20 [04:52<02:04, 20.72s/it]
Task 0, Epoch 15/20 => Loss 0.244, Train_accy 91.42:  70%|███████   | 14/20 [05:12<02:04, 20.72s/it]
Task 0, Epoch 15/20 => Loss 0.244, Train_accy 91.42:  75%|███████▌  | 15/20 [05:12<01:43, 20.64s/it]
Task 0, Epoch 16/20 => Loss 0.275, Train_accy 91.64, Test_accy 96.50:  75%|███████▌  | 15/20 [05:35<01:43, 20.64s/it]
Task 0, Epoch 16/20 => Loss 0.275, Train_accy 91.64, Test_accy 96.50:  80%|████████  | 16/20 [05:35<01:24, 21.20s/it]
Task 0, Epoch 17/20 => Loss 0.259, Train_accy 91.10:  80%|████████  | 16/20 [05:55<01:24, 21.20s/it]                 
Task 0, Epoch 17/20 => Loss 0.259, Train_accy 91.10:  85%|████████▌ | 17/20 [05:55<01:02, 20.97s/it]
Task 0, Epoch 18/20 => Loss 0.251, Train_accy 91.68:  85%|████████▌ | 17/20 [06:16<01:02, 20.97s/it]
Task 0, Epoch 18/20 => Loss 0.251, Train_accy 91.68:  90%|█████████ | 18/20 [06:16<00:41, 20.81s/it]
Task 0, Epoch 19/20 => Loss 0.257, Train_accy 92.16:  90%|█████████ | 18/20 [06:36<00:41, 20.81s/it]
Task 0, Epoch 19/20 => Loss 0.257, Train_accy 92.16:  95%|█████████▌| 19/20 [06:36<00:20, 20.70s/it]
Task 0, Epoch 20/20 => Loss 0.238, Train_accy 91.96:  95%|█████████▌| 19/20 [06:57<00:20, 20.70s/it]
Task 0, Epoch 20/20 => Loss 0.238, Train_accy 91.96: 100%|██████████| 20/20 [06:57<00:00, 20.62s/it]
Task 0, Epoch 20/20 => Loss 0.238, Train_accy 91.96: 100%|██████████| 20/20 [06:57<00:00, 20.85s/it]
2025-11-10 20:24:42,188 [sdfourier.py] => Task 0, Epoch 20/20 => Loss 0.238, Train_accy 91.96
2025-11-10 20:24:42,191 [trainer.py] => All params: 185789578
2025-11-10 20:24:42,192 [trainer.py] => Trainable params: 36490
/mnt/weitao/SD-Lora-CL-main/utils/toolkit.py:60: RuntimeWarning: invalid value encountered in scalar divide
  (y_pred[idxes] == y_true[idxes]).sum() * 100 / len(idxes), decimals=2
2025-11-10 20:24:44,252 [trainer.py] => No NME accuracy.
2025-11-10 20:24:44,253 [trainer.py] => CNN: {'total': np.float64(96.3), '00-09': np.float64(96.3), 'old': np.float64(96.3), 'new': np.float64(nan)}
2025-11-10 20:24:44,253 [trainer.py] => CNN top1 curve: [np.float64(96.3)]
2025-11-10 20:24:44,253 [trainer.py] => CNN top5 curve: [np.float64(99.8)]

Average Accuracy (CNN): 96.3
2025-11-10 20:24:44,253 [trainer.py] => Average Accuracy (CNN): 96.3 

task 1
2025-11-10 20:24:44,253 [sdfourier.py] => Learning on 10-20

总共重置了 12 个模块的qkv层权重

  0%|          | 0/20 [00:00<?, ?it/s]
Task 1, Epoch 1/20 => Loss 0.811, Train_accy 64.96, Test_accy 89.20:   0%|          | 0/20 [00:12<?, ?it/s]
Task 1, Epoch 1/20 => Loss 0.811, Train_accy 64.96, Test_accy 89.20:   5%|▌         | 1/20 [00:12<04:00, 12.68s/it]
Task 1, Epoch 2/20 => Loss 0.414, Train_accy 85.26:   5%|▌         | 1/20 [00:21<04:00, 12.68s/it]                 
Task 1, Epoch 2/20 => Loss 0.414, Train_accy 85.26:  10%|█         | 2/20 [00:21<03:08, 10.47s/it]
Task 1, Epoch 3/20 => Loss 0.323, Train_accy 86.32:  10%|█         | 2/20 [00:30<03:08, 10.47s/it]
Task 1, Epoch 3/20 => Loss 0.323, Train_accy 86.32:  15%|█▌        | 3/20 [00:30<02:45,  9.76s/it]
Task 1, Epoch 4/20 => Loss 0.322, Train_accy 85.58:  15%|█▌        | 3/20 [00:39<02:45,  9.76s/it]
Task 1, Epoch 4/20 => Loss 0.322, Train_accy 85.58:  20%|██        | 4/20 [00:39<02:30,  9.43s/it]
Task 1, Epoch 5/20 => Loss 0.314, Train_accy 85.22:  20%|██        | 4/20 [00:48<02:30,  9.43s/it]
Task 1, Epoch 5/20 => Loss 0.314, Train_accy 85.22:  25%|██▌       | 5/20 [00:48<02:18,  9.25s/it]
Task 1, Epoch 6/20 => Loss 0.302, Train_accy 86.06, Test_accy 91.90:  25%|██▌       | 5/20 [01:01<02:18,  9.25s/it]
Task 1, Epoch 6/20 => Loss 0.302, Train_accy 86.06, Test_accy 91.90:  30%|███       | 6/20 [01:01<02:25, 10.42s/it]
Task 1, Epoch 7/20 => Loss 0.331, Train_accy 84.92:  30%|███       | 6/20 [01:09<02:25, 10.42s/it]                 
Task 1, Epoch 7/20 => Loss 0.331, Train_accy 84.92:  35%|███▌      | 7/20 [01:09<02:09,  9.93s/it]
Task 1, Epoch 8/20 => Loss 0.277, Train_accy 87.04:  35%|███▌      | 7/20 [01:18<02:09,  9.93s/it]
Task 1, Epoch 8/20 => Loss 0.277, Train_accy 87.04:  40%|████      | 8/20 [01:18<01:55,  9.62s/it]
Task 1, Epoch 9/20 => Loss 0.306, Train_accy 86.04:  40%|████      | 8/20 [01:27<01:55,  9.62s/it]
Task 1, Epoch 9/20 => Loss 0.306, Train_accy 86.04:  45%|████▌     | 9/20 [01:27<01:43,  9.40s/it]
Task 1, Epoch 10/20 => Loss 0.268, Train_accy 87.06:  45%|████▌     | 9/20 [01:36<01:43,  9.40s/it]
Task 1, Epoch 10/20 => Loss 0.268, Train_accy 87.06:  50%|█████     | 10/20 [01:36<01:32,  9.25s/it]
Task 1, Epoch 11/20 => Loss 0.298, Train_accy 86.10, Test_accy 92.40:  50%|█████     | 10/20 [01:49<01:32,  9.25s/it]
Task 1, Epoch 11/20 => Loss 0.298, Train_accy 86.10, Test_accy 92.40:  55%|█████▌    | 11/20 [01:49<01:33, 10.34s/it]
Task 1, Epoch 12/20 => Loss 0.268, Train_accy 86.26:  55%|█████▌    | 11/20 [01:58<01:33, 10.34s/it]                 
Task 1, Epoch 12/20 => Loss 0.268, Train_accy 86.26:  60%|██████    | 12/20 [01:58<01:19,  9.92s/it]
Task 1, Epoch 13/20 => Loss 0.234, Train_accy 87.44:  60%|██████    | 12/20 [02:07<01:19,  9.92s/it]
Task 1, Epoch 13/20 => Loss 0.234, Train_accy 87.44:  65%|██████▌   | 13/20 [02:07<01:07,  9.62s/it]
Task 1, Epoch 14/20 => Loss 0.246, Train_accy 87.30:  65%|██████▌   | 13/20 [02:16<01:07,  9.62s/it]
Task 1, Epoch 14/20 => Loss 0.246, Train_accy 87.30:  70%|███████   | 14/20 [02:16<00:56,  9.41s/it]
Task 1, Epoch 15/20 => Loss 0.232, Train_accy 87.24:  70%|███████   | 14/20 [02:25<00:56,  9.41s/it]
Task 1, Epoch 15/20 => Loss 0.232, Train_accy 87.24:  75%|███████▌  | 15/20 [02:25<00:46,  9.27s/it]
Task 1, Epoch 16/20 => Loss 0.239, Train_accy 87.16, Test_accy 92.40:  75%|███████▌  | 15/20 [02:38<00:46,  9.27s/it]
Task 1, Epoch 16/20 => Loss 0.239, Train_accy 87.16, Test_accy 92.40:  80%|████████  | 16/20 [02:38<00:41, 10.31s/it]
Task 1, Epoch 17/20 => Loss 0.249, Train_accy 86.84:  80%|████████  | 16/20 [02:46<00:41, 10.31s/it]                 
Task 1, Epoch 17/20 => Loss 0.249, Train_accy 86.84:  85%|████████▌ | 17/20 [02:46<00:29,  9.89s/it]
Task 1, Epoch 18/20 => Loss 0.223, Train_accy 87.72:  85%|████████▌ | 17/20 [02:55<00:29,  9.89s/it]
Task 1, Epoch 18/20 => Loss 0.223, Train_accy 87.72:  90%|█████████ | 18/20 [02:55<00:19,  9.61s/it]
Task 1, Epoch 19/20 => Loss 0.247, Train_accy 87.00:  90%|█████████ | 18/20 [03:04<00:19,  9.61s/it]
Task 1, Epoch 19/20 => Loss 0.247, Train_accy 87.00:  95%|█████████▌| 19/20 [03:04<00:09,  9.41s/it]
Task 1, Epoch 20/20 => Loss 0.244, Train_accy 86.92:  95%|█████████▌| 19/20 [03:13<00:09,  9.41s/it]
Task 1, Epoch 20/20 => Loss 0.244, Train_accy 86.92: 100%|██████████| 20/20 [03:13<00:00,  9.27s/it]
Task 1, Epoch 20/20 => Loss 0.244, Train_accy 86.92: 100%|██████████| 20/20 [03:13<00:00,  9.69s/it]
2025-11-10 20:27:58,816 [sdfourier.py] => Task 1, Epoch 20/20 => Loss 0.244, Train_accy 86.92
2025-11-10 20:27:58,818 [trainer.py] => All params: 185830868
2025-11-10 20:27:58,819 [trainer.py] => Trainable params: 44180
2025-11-10 20:28:02,582 [trainer.py] => No NME accuracy.
2025-11-10 20:28:02,582 [trainer.py] => CNN: {'total': np.float64(92.5), '00-09': np.float64(91.8), '10-19': np.float64(93.2), 'old': np.float64(92.5), 'new': np.float64(nan)}
2025-11-10 20:28:02,582 [trainer.py] => CNN top1 curve: [np.float64(96.3), np.float64(92.5)]
2025-11-10 20:28:02,582 [trainer.py] => CNN top5 curve: [np.float64(99.8), np.float64(99.3)]

Average Accuracy (CNN): 94.4
2025-11-10 20:28:02,582 [trainer.py] => Average Accuracy (CNN): 94.4 

task 2
2025-11-10 20:28:02,583 [sdfourier.py] => Learning on 20-30

总共重置了 12 个模块的qkv层权重

  0%|          | 0/20 [00:00<?, ?it/s]
Task 2, Epoch 1/20 => Loss 0.795, Train_accy 58.96, Test_accy 87.90:   0%|          | 0/20 [00:14<?, ?it/s]
Task 2, Epoch 1/20 => Loss 0.795, Train_accy 58.96, Test_accy 87.90:   5%|▌         | 1/20 [00:14<04:34, 14.44s/it]
Task 2, Epoch 2/20 => Loss 0.480, Train_accy 79.86:   5%|▌         | 1/20 [00:23<04:34, 14.44s/it]                 
Task 2, Epoch 2/20 => Loss 0.480, Train_accy 79.86:  10%|█         | 2/20 [00:23<03:21, 11.20s/it]
Task 2, Epoch 3/20 => Loss 0.478, Train_accy 80.02:  10%|█         | 2/20 [00:32<03:21, 11.20s/it]
Task 2, Epoch 3/20 => Loss 0.478, Train_accy 80.02:  15%|█▌        | 3/20 [00:32<02:52, 10.16s/it]
Task 2, Epoch 4/20 => Loss 0.464, Train_accy 79.72:  15%|█▌        | 3/20 [00:41<02:52, 10.16s/it]
Task 2, Epoch 4/20 => Loss 0.464, Train_accy 79.72:  20%|██        | 4/20 [00:41<02:34,  9.67s/it]
Task 2, Epoch 5/20 => Loss 0.431, Train_accy 79.86:  20%|██        | 4/20 [00:50<02:34,  9.67s/it]
Task 2, Epoch 5/20 => Loss 0.431, Train_accy 79.86:  25%|██▌       | 5/20 [00:50<02:21,  9.41s/it]
Task 2, Epoch 6/20 => Loss 0.405, Train_accy 80.64, Test_accy 89.07:  25%|██▌       | 5/20 [01:04<02:21,  9.41s/it]
Task 2, Epoch 6/20 => Loss 0.405, Train_accy 80.64, Test_accy 89.07:  30%|███       | 6/20 [01:04<02:36, 11.15s/it]
Task 2, Epoch 7/20 => Loss 0.475, Train_accy 80.04:  30%|███       | 6/20 [01:13<02:36, 11.15s/it]                 
Task 2, Epoch 7/20 => Loss 0.475, Train_accy 80.04:  35%|███▌      | 7/20 [01:13<02:15, 10.42s/it]
Task 2, Epoch 8/20 => Loss 0.382, Train_accy 81.04:  35%|███▌      | 7/20 [01:22<02:15, 10.42s/it]
Task 2, Epoch 8/20 => Loss 0.382, Train_accy 81.04:  40%|████      | 8/20 [01:22<01:59,  9.94s/it]
Task 2, Epoch 9/20 => Loss 0.371, Train_accy 81.04:  40%|████      | 8/20 [01:31<01:59,  9.94s/it]
Task 2, Epoch 9/20 => Loss 0.371, Train_accy 81.04:  45%|████▌     | 9/20 [01:31<01:45,  9.62s/it]
Task 2, Epoch 10/20 => Loss 0.348, Train_accy 81.62:  45%|████▌     | 9/20 [01:40<01:45,  9.62s/it]
Task 2, Epoch 10/20 => Loss 0.348, Train_accy 81.62:  50%|█████     | 10/20 [01:40<01:34,  9.47s/it]
Task 2, Epoch 11/20 => Loss 0.333, Train_accy 81.96, Test_accy 89.13:  50%|█████     | 10/20 [01:55<01:34,  9.47s/it]
Task 2, Epoch 11/20 => Loss 0.333, Train_accy 81.96, Test_accy 89.13:  55%|█████▌    | 11/20 [01:55<01:39, 11.11s/it]
Task 2, Epoch 12/20 => Loss 0.356, Train_accy 81.44:  55%|█████▌    | 11/20 [02:04<01:39, 11.11s/it]                 
Task 2, Epoch 12/20 => Loss 0.356, Train_accy 81.44:  60%|██████    | 12/20 [02:04<01:24, 10.50s/it]
Task 2, Epoch 13/20 => Loss 0.360, Train_accy 81.54:  60%|██████    | 12/20 [02:13<01:24, 10.50s/it]
Task 2, Epoch 13/20 => Loss 0.360, Train_accy 81.54:  65%|██████▌   | 13/20 [02:13<01:10, 10.07s/it]
Task 2, Epoch 14/20 => Loss 0.367, Train_accy 81.38:  65%|██████▌   | 13/20 [02:22<01:10, 10.07s/it]
Task 2, Epoch 14/20 => Loss 0.367, Train_accy 81.38:  70%|███████   | 14/20 [02:22<00:58,  9.77s/it]
Task 2, Epoch 15/20 => Loss 0.324, Train_accy 81.50:  70%|███████   | 14/20 [02:31<00:58,  9.77s/it]
Task 2, Epoch 15/20 => Loss 0.324, Train_accy 81.50:  75%|███████▌  | 15/20 [02:31<00:47,  9.55s/it]
Task 2, Epoch 16/20 => Loss 0.323, Train_accy 81.56, Test_accy 89.50:  75%|███████▌  | 15/20 [02:46<00:47,  9.55s/it]
Task 2, Epoch 16/20 => Loss 0.323, Train_accy 81.56, Test_accy 89.50:  80%|████████  | 16/20 [02:46<00:44, 11.09s/it]
Task 2, Epoch 17/20 => Loss 0.314, Train_accy 81.92:  80%|████████  | 16/20 [02:55<00:44, 11.09s/it]                 
Task 2, Epoch 17/20 => Loss 0.314, Train_accy 81.92:  85%|████████▌ | 17/20 [02:55<00:31, 10.48s/it]
Task 2, Epoch 18/20 => Loss 0.311, Train_accy 82.22:  85%|████████▌ | 17/20 [03:04<00:31, 10.48s/it]
Task 2, Epoch 18/20 => Loss 0.311, Train_accy 82.22:  90%|█████████ | 18/20 [03:04<00:20, 10.06s/it]
Task 2, Epoch 19/20 => Loss 0.315, Train_accy 82.04:  90%|█████████ | 18/20 [03:13<00:20, 10.06s/it]
Task 2, Epoch 19/20 => Loss 0.315, Train_accy 82.04:  95%|█████████▌| 19/20 [03:13<00:09,  9.76s/it]
Task 2, Epoch 20/20 => Loss 0.313, Train_accy 81.58:  95%|█████████▌| 19/20 [03:22<00:09,  9.76s/it]
Task 2, Epoch 20/20 => Loss 0.313, Train_accy 81.58: 100%|██████████| 20/20 [03:22<00:00,  9.57s/it]
Task 2, Epoch 20/20 => Loss 0.313, Train_accy 81.58: 100%|██████████| 20/20 [03:22<00:00, 10.13s/it]
2025-11-10 20:31:26,335 [sdfourier.py] => Task 2, Epoch 20/20 => Loss 0.313, Train_accy 81.58
2025-11-10 20:31:26,338 [trainer.py] => All params: 185876958
2025-11-10 20:31:26,339 [trainer.py] => Trainable params: 51870
2025-11-10 20:31:31,914 [trainer.py] => No NME accuracy.
2025-11-10 20:31:31,914 [trainer.py] => CNN: {'total': np.float64(89.53), '00-09': np.float64(89.7), '10-19': np.float64(89.0), '20-29': np.float64(89.9), 'old': np.float64(89.53), 'new': np.float64(nan)}
2025-11-10 20:31:31,914 [trainer.py] => CNN top1 curve: [np.float64(96.3), np.float64(92.5), np.float64(89.53)]
2025-11-10 20:31:31,914 [trainer.py] => CNN top5 curve: [np.float64(99.8), np.float64(99.3), np.float64(99.0)]

Average Accuracy (CNN): 92.77666666666669
2025-11-10 20:31:31,914 [trainer.py] => Average Accuracy (CNN): 92.77666666666669 

task 3
2025-11-10 20:31:31,915 [sdfourier.py] => Learning on 30-40

总共重置了 12 个模块的qkv层权重

  0%|          | 0/20 [00:00<?, ?it/s]
Task 3, Epoch 1/20 => Loss 0.767, Train_accy 54.16, Test_accy 85.85:   0%|          | 0/20 [00:16<?, ?it/s]
Task 3, Epoch 1/20 => Loss 0.767, Train_accy 54.16, Test_accy 85.85:   5%|▌         | 1/20 [00:16<05:11, 16.41s/it]
Task 3, Epoch 2/20 => Loss 0.379, Train_accy 76.32:   5%|▌         | 1/20 [00:25<05:11, 16.41s/it]                 
Task 3, Epoch 2/20 => Loss 0.379, Train_accy 76.32:  10%|█         | 2/20 [00:25<03:37, 12.09s/it]
Task 3, Epoch 3/20 => Loss 0.324, Train_accy 75.74:  10%|█         | 2/20 [00:34<03:37, 12.09s/it]
Task 3, Epoch 3/20 => Loss 0.324, Train_accy 75.74:  15%|█▌        | 3/20 [00:34<03:02, 10.71s/it]
Task 3, Epoch 4/20 => Loss 0.302, Train_accy 75.60:  15%|█▌        | 3/20 [00:43<03:02, 10.71s/it]
Task 3, Epoch 4/20 => Loss 0.302, Train_accy 75.60:  20%|██        | 4/20 [00:43<02:40, 10.06s/it]
Task 3, Epoch 5/20 => Loss 0.290, Train_accy 74.44:  20%|██        | 4/20 [00:52<02:40, 10.06s/it]
Task 3, Epoch 5/20 => Loss 0.290, Train_accy 74.44:  25%|██▌       | 5/20 [00:52<02:25,  9.71s/it]
Task 3, Epoch 6/20 => Loss 0.260, Train_accy 75.60, Test_accy 87.68:  25%|██▌       | 5/20 [01:09<02:25,  9.71s/it]
Task 3, Epoch 6/20 => Loss 0.260, Train_accy 75.60, Test_accy 87.68:  30%|███       | 6/20 [01:09<02:47, 11.98s/it]
Task 3, Epoch 7/20 => Loss 0.277, Train_accy 76.00:  30%|███       | 6/20 [01:18<02:47, 11.98s/it]                 
Task 3, Epoch 7/20 => Loss 0.277, Train_accy 76.00:  35%|███▌      | 7/20 [01:18<02:23, 11.03s/it]
Task 3, Epoch 8/20 => Loss 0.291, Train_accy 75.58:  35%|███▌      | 7/20 [01:27<02:23, 11.03s/it]
Task 3, Epoch 8/20 => Loss 0.291, Train_accy 75.58:  40%|████      | 8/20 [01:27<02:04, 10.41s/it]
Task 3, Epoch 9/20 => Loss 0.255, Train_accy 74.66:  40%|████      | 8/20 [01:36<02:04, 10.41s/it]
Task 3, Epoch 9/20 => Loss 0.255, Train_accy 74.66:  45%|████▌     | 9/20 [01:36<01:49, 10.00s/it]
Task 3, Epoch 10/20 => Loss 0.266, Train_accy 75.40:  45%|████▌     | 9/20 [01:45<01:49, 10.00s/it]
Task 3, Epoch 10/20 => Loss 0.266, Train_accy 75.40:  50%|█████     | 10/20 [01:45<01:37,  9.71s/it]
Task 3, Epoch 11/20 => Loss 0.258, Train_accy 75.64, Test_accy 87.62:  50%|█████     | 10/20 [02:01<01:37,  9.71s/it]
Task 3, Epoch 11/20 => Loss 0.258, Train_accy 75.64, Test_accy 87.62:  55%|█████▌    | 11/20 [02:01<01:45, 11.76s/it]
Task 3, Epoch 12/20 => Loss 0.254, Train_accy 74.26:  55%|█████▌    | 11/20 [02:10<01:45, 11.76s/it]                 
Task 3, Epoch 12/20 => Loss 0.254, Train_accy 74.26:  60%|██████    | 12/20 [02:10<01:27, 10.95s/it]
Task 3, Epoch 13/20 => Loss 0.262, Train_accy 74.84:  60%|██████    | 12/20 [02:20<01:27, 10.95s/it]
Task 3, Epoch 13/20 => Loss 0.262, Train_accy 74.84:  65%|██████▌   | 13/20 [02:20<01:12, 10.40s/it]
Task 3, Epoch 14/20 => Loss 0.239, Train_accy 74.90:  65%|██████▌   | 13/20 [02:29<01:12, 10.40s/it]
Task 3, Epoch 14/20 => Loss 0.239, Train_accy 74.90:  70%|███████   | 14/20 [02:29<01:00, 10.01s/it]
Task 3, Epoch 15/20 => Loss 0.231, Train_accy 75.90:  70%|███████   | 14/20 [02:38<01:00, 10.01s/it]
Task 3, Epoch 15/20 => Loss 0.231, Train_accy 75.90:  75%|███████▌  | 15/20 [02:38<00:48,  9.73s/it]
Task 3, Epoch 16/20 => Loss 0.233, Train_accy 74.62, Test_accy 87.92:  75%|███████▌  | 15/20 [02:54<00:48,  9.73s/it]
Task 3, Epoch 16/20 => Loss 0.233, Train_accy 74.62, Test_accy 87.92:  80%|████████  | 16/20 [02:54<00:47, 11.76s/it]
Task 3, Epoch 17/20 => Loss 0.222, Train_accy 75.82:  80%|████████  | 16/20 [03:03<00:47, 11.76s/it]                 
Task 3, Epoch 17/20 => Loss 0.222, Train_accy 75.82:  85%|████████▌ | 17/20 [03:03<00:33, 11.00s/it]
Task 3, Epoch 18/20 => Loss 0.224, Train_accy 75.14:  85%|████████▌ | 17/20 [03:13<00:33, 11.00s/it]
Task 3, Epoch 18/20 => Loss 0.224, Train_accy 75.14:  90%|█████████ | 18/20 [03:13<00:20, 10.43s/it]
Task 3, Epoch 19/20 => Loss 0.242, Train_accy 74.72:  90%|█████████ | 18/20 [03:22<00:20, 10.43s/it]
Task 3, Epoch 19/20 => Loss 0.242, Train_accy 74.72:  95%|█████████▌| 19/20 [03:22<00:10, 10.04s/it]
Task 3, Epoch 20/20 => Loss 0.234, Train_accy 74.84:  95%|█████████▌| 19/20 [03:31<00:10, 10.04s/it]
Task 3, Epoch 20/20 => Loss 0.234, Train_accy 74.84: 100%|██████████| 20/20 [03:31<00:00,  9.76s/it]
Task 3, Epoch 20/20 => Loss 0.234, Train_accy 74.84: 100%|██████████| 20/20 [03:31<00:00, 10.56s/it]
2025-11-10 20:35:04,750 [sdfourier.py] => Task 3, Epoch 20/20 => Loss 0.234, Train_accy 74.84
2025-11-10 20:35:04,752 [trainer.py] => All params: 185927848
2025-11-10 20:35:04,753 [trainer.py] => Trainable params: 59560
2025-11-10 20:35:12,125 [trainer.py] => No NME accuracy.
2025-11-10 20:35:12,125 [trainer.py] => CNN: {'total': np.float64(87.8), '00-09': np.float64(87.9), '10-19': np.float64(86.0), '20-29': np.float64(87.8), '30-39': np.float64(89.5), 'old': np.float64(87.8), 'new': np.float64(nan)}
2025-11-10 20:35:12,125 [trainer.py] => CNN top1 curve: [np.float64(96.3), np.float64(92.5), np.float64(89.53), np.float64(87.8)]
2025-11-10 20:35:12,125 [trainer.py] => CNN top5 curve: [np.float64(99.8), np.float64(99.3), np.float64(99.0), np.float64(98.58)]

Average Accuracy (CNN): 91.53250000000001
2025-11-10 20:35:12,125 [trainer.py] => Average Accuracy (CNN): 91.53250000000001 

task 4
2025-11-10 20:35:12,126 [sdfourier.py] => Learning on 40-50

总共重置了 12 个模块的qkv层权重

  0%|          | 0/20 [00:00<?, ?it/s]
Task 4, Epoch 1/20 => Loss 0.790, Train_accy 50.58, Test_accy 84.48:   0%|          | 0/20 [00:18<?, ?it/s]
Task 4, Epoch 1/20 => Loss 0.790, Train_accy 50.58, Test_accy 84.48:   5%|▌         | 1/20 [00:18<05:45, 18.17s/it]
Task 4, Epoch 2/20 => Loss 0.430, Train_accy 74.52:   5%|▌         | 1/20 [00:27<05:45, 18.17s/it]                 
Task 4, Epoch 2/20 => Loss 0.430, Train_accy 74.52:  10%|█         | 2/20 [00:27<03:50, 12.82s/it]
Task 4, Epoch 3/20 => Loss 0.371, Train_accy 72.24:  10%|█         | 2/20 [00:36<03:50, 12.82s/it]
Task 4, Epoch 3/20 => Loss 0.371, Train_accy 72.24:  15%|█▌        | 3/20 [00:36<03:08, 11.11s/it]
Task 4, Epoch 4/20 => Loss 0.364, Train_accy 71.46:  15%|█▌        | 3/20 [00:45<03:08, 11.11s/it]
Task 4, Epoch 4/20 => Loss 0.364, Train_accy 71.46:  20%|██        | 4/20 [00:45<02:44, 10.31s/it]
Task 4, Epoch 5/20 => Loss 0.332, Train_accy 71.52:  20%|██        | 4/20 [00:54<02:44, 10.31s/it]
Task 4, Epoch 5/20 => Loss 0.332, Train_accy 71.52:  25%|██▌       | 5/20 [00:54<02:28,  9.87s/it]
Task 4, Epoch 6/20 => Loss 0.349, Train_accy 72.60, Test_accy 85.96:  25%|██▌       | 5/20 [01:12<02:28,  9.87s/it]
Task 4, Epoch 6/20 => Loss 0.349, Train_accy 72.60, Test_accy 85.96:  30%|███       | 6/20 [01:12<02:57, 12.71s/it]
Task 4, Epoch 7/20 => Loss 0.331, Train_accy 72.06:  30%|███       | 6/20 [01:21<02:57, 12.71s/it]                 
Task 4, Epoch 7/20 => Loss 0.331, Train_accy 72.06:  35%|███▌      | 7/20 [01:21<02:29, 11.52s/it]
Task 4, Epoch 8/20 => Loss 0.298, Train_accy 71.72:  35%|███▌      | 7/20 [01:30<02:29, 11.52s/it]
Task 4, Epoch 8/20 => Loss 0.298, Train_accy 71.72:  40%|████      | 8/20 [01:30<02:08, 10.75s/it]
Task 4, Epoch 9/20 => Loss 0.292, Train_accy 71.96:  40%|████      | 8/20 [01:39<02:08, 10.75s/it]
Task 4, Epoch 9/20 => Loss 0.292, Train_accy 71.96:  45%|████▌     | 9/20 [01:39<01:52, 10.22s/it]
Task 4, Epoch 10/20 => Loss 0.284, Train_accy 72.80:  45%|████▌     | 9/20 [01:49<01:52, 10.22s/it]
Task 4, Epoch 10/20 => Loss 0.284, Train_accy 72.80:  50%|█████     | 10/20 [01:49<01:38,  9.87s/it]
Task 4, Epoch 11/20 => Loss 0.258, Train_accy 73.18, Test_accy 86.24:  50%|█████     | 10/20 [02:07<01:38,  9.87s/it]
Task 4, Epoch 11/20 => Loss 0.258, Train_accy 73.18, Test_accy 86.24:  55%|█████▌    | 11/20 [02:07<01:51, 12.40s/it]
Task 4, Epoch 12/20 => Loss 0.255, Train_accy 71.98:  55%|█████▌    | 11/20 [02:16<01:51, 12.40s/it]                 
Task 4, Epoch 12/20 => Loss 0.255, Train_accy 71.98:  60%|██████    | 12/20 [02:16<01:31, 11.39s/it]
Task 4, Epoch 13/20 => Loss 0.264, Train_accy 72.00:  60%|██████    | 12/20 [02:25<01:31, 11.39s/it]
Task 4, Epoch 13/20 => Loss 0.264, Train_accy 72.00:  65%|██████▌   | 13/20 [02:25<01:14, 10.69s/it]
Task 4, Epoch 14/20 => Loss 0.252, Train_accy 73.04:  65%|██████▌   | 13/20 [02:34<01:14, 10.69s/it]
Task 4, Epoch 14/20 => Loss 0.252, Train_accy 73.04:  70%|███████   | 14/20 [02:34<01:01, 10.20s/it]
Task 4, Epoch 15/20 => Loss 0.259, Train_accy 72.36:  70%|███████   | 14/20 [02:43<01:01, 10.20s/it]
Task 4, Epoch 15/20 => Loss 0.259, Train_accy 72.36:  75%|███████▌  | 15/20 [02:43<00:49,  9.91s/it]
Task 4, Epoch 16/20 => Loss 0.239, Train_accy 72.94, Test_accy 86.16:  75%|███████▌  | 15/20 [03:01<00:49,  9.91s/it]
Task 4, Epoch 16/20 => Loss 0.239, Train_accy 72.94, Test_accy 86.16:  80%|████████  | 16/20 [03:01<00:49, 12.41s/it]
Task 4, Epoch 17/20 => Loss 0.240, Train_accy 73.48:  80%|████████  | 16/20 [03:10<00:49, 12.41s/it]                 
Task 4, Epoch 17/20 => Loss 0.240, Train_accy 73.48:  85%|████████▌ | 17/20 [03:10<00:34, 11.42s/it]
Task 4, Epoch 18/20 => Loss 0.246, Train_accy 71.94:  85%|████████▌ | 17/20 [03:20<00:34, 11.42s/it]
Task 4, Epoch 18/20 => Loss 0.246, Train_accy 71.94:  90%|█████████ | 18/20 [03:20<00:21, 10.73s/it]
Task 4, Epoch 19/20 => Loss 0.236, Train_accy 73.46:  90%|█████████ | 18/20 [03:29<00:21, 10.73s/it]
Task 4, Epoch 19/20 => Loss 0.236, Train_accy 73.46:  95%|█████████▌| 19/20 [03:29<00:10, 10.24s/it]
Task 4, Epoch 20/20 => Loss 0.230, Train_accy 73.10:  95%|█████████▌| 19/20 [03:38<00:10, 10.24s/it]
Task 4, Epoch 20/20 => Loss 0.230, Train_accy 73.10: 100%|██████████| 20/20 [03:38<00:00,  9.88s/it]
Task 4, Epoch 20/20 => Loss 0.230, Train_accy 73.10: 100%|██████████| 20/20 [03:38<00:00, 10.91s/it]
2025-11-10 20:38:52,452 [sdfourier.py] => Task 4, Epoch 20/20 => Loss 0.230, Train_accy 73.10
2025-11-10 20:38:52,455 [trainer.py] => All params: 185983538
2025-11-10 20:38:52,456 [trainer.py] => Trainable params: 67250
2025-11-10 20:39:01,529 [trainer.py] => No NME accuracy.
2025-11-10 20:39:01,529 [trainer.py] => CNN: {'total': np.float64(86.08), '00-09': np.float64(84.9), '10-19': np.float64(85.5), '20-29': np.float64(87.3), '30-39': np.float64(86.7), '40-49': np.float64(86.0), 'old': np.float64(86.08), 'new': np.float64(nan)}
2025-11-10 20:39:01,529 [trainer.py] => CNN top1 curve: [np.float64(96.3), np.float64(92.5), np.float64(89.53), np.float64(87.8), np.float64(86.08)]
2025-11-10 20:39:01,529 [trainer.py] => CNN top5 curve: [np.float64(99.8), np.float64(99.3), np.float64(99.0), np.float64(98.58), np.float64(97.98)]

Average Accuracy (CNN): 90.44200000000001
2025-11-10 20:39:01,529 [trainer.py] => Average Accuracy (CNN): 90.44200000000001 

task 5
2025-11-10 20:39:01,530 [sdfourier.py] => Learning on 50-60

总共重置了 12 个模块的qkv层权重

  0%|          | 0/20 [00:00<?, ?it/s]
Task 5, Epoch 1/20 => Loss 0.721, Train_accy 48.44, Test_accy 84.48:   0%|          | 0/20 [00:19<?, ?it/s]
Task 5, Epoch 1/20 => Loss 0.721, Train_accy 48.44, Test_accy 84.48:   5%|▌         | 1/20 [00:19<06:17, 19.87s/it]
Task 5, Epoch 2/20 => Loss 0.454, Train_accy 73.18:   5%|▌         | 1/20 [00:28<06:17, 19.87s/it]                 
Task 5, Epoch 2/20 => Loss 0.454, Train_accy 73.18:  10%|█         | 2/20 [00:28<04:03, 13.53s/it]
Task 5, Epoch 3/20 => Loss 0.356, Train_accy 73.26:  10%|█         | 2/20 [00:38<04:03, 13.53s/it]
Task 5, Epoch 3/20 => Loss 0.356, Train_accy 73.26:  15%|█▌        | 3/20 [00:38<03:15, 11.50s/it]
Task 5, Epoch 4/20 => Loss 0.361, Train_accy 72.52:  15%|█▌        | 3/20 [00:47<03:15, 11.50s/it]
Task 5, Epoch 4/20 => Loss 0.361, Train_accy 72.52:  20%|██        | 4/20 [00:47<02:48, 10.56s/it]
Task 5, Epoch 5/20 => Loss 0.322, Train_accy 73.74:  20%|██        | 4/20 [00:56<02:48, 10.56s/it]
Task 5, Epoch 5/20 => Loss 0.322, Train_accy 73.74:  25%|██▌       | 5/20 [00:56<02:30, 10.03s/it]
Task 5, Epoch 6/20 => Loss 0.323, Train_accy 71.52, Test_accy 85.37:  25%|██▌       | 5/20 [01:16<02:30, 10.03s/it]
Task 5, Epoch 6/20 => Loss 0.323, Train_accy 71.52, Test_accy 85.37:  30%|███       | 6/20 [01:16<03:07, 13.41s/it]
Task 5, Epoch 7/20 => Loss 0.335, Train_accy 71.76:  30%|███       | 6/20 [01:25<03:07, 13.41s/it]                 
Task 5, Epoch 7/20 => Loss 0.335, Train_accy 71.76:  35%|███▌      | 7/20 [01:25<02:35, 11.99s/it]
Task 5, Epoch 8/20 => Loss 0.302, Train_accy 72.14:  35%|███▌      | 7/20 [01:34<02:35, 11.99s/it]
Task 5, Epoch 8/20 => Loss 0.302, Train_accy 72.14:  40%|████      | 8/20 [01:34<02:12, 11.07s/it]
Task 5, Epoch 9/20 => Loss 0.310, Train_accy 72.90:  40%|████      | 8/20 [01:43<02:12, 11.07s/it]
Task 5, Epoch 9/20 => Loss 0.310, Train_accy 72.90:  45%|████▌     | 9/20 [01:43<01:54, 10.45s/it]
Task 5, Epoch 10/20 => Loss 0.292, Train_accy 72.38:  45%|████▌     | 9/20 [01:52<01:54, 10.45s/it]
Task 5, Epoch 10/20 => Loss 0.292, Train_accy 72.38:  50%|█████     | 10/20 [01:52<01:40, 10.04s/it]
Task 5, Epoch 11/20 => Loss 0.290, Train_accy 73.18, Test_accy 85.13:  50%|█████     | 10/20 [02:12<01:40, 10.04s/it]
Task 5, Epoch 11/20 => Loss 0.290, Train_accy 73.18, Test_accy 85.13:  55%|█████▌    | 11/20 [02:12<01:57, 13.05s/it]
Task 5, Epoch 12/20 => Loss 0.299, Train_accy 72.94:  55%|█████▌    | 11/20 [02:21<01:57, 13.05s/it]                 
Task 5, Epoch 12/20 => Loss 0.299, Train_accy 72.94:  60%|██████    | 12/20 [02:21<01:34, 11.85s/it]
Task 5, Epoch 13/20 => Loss 0.290, Train_accy 72.06:  60%|██████    | 12/20 [02:30<01:34, 11.85s/it]
Task 5, Epoch 13/20 => Loss 0.290, Train_accy 72.06:  65%|██████▌   | 13/20 [02:30<01:17, 11.02s/it]
Task 5, Epoch 14/20 => Loss 0.265, Train_accy 72.28:  65%|██████▌   | 13/20 [02:39<01:17, 11.02s/it]
Task 5, Epoch 14/20 => Loss 0.265, Train_accy 72.28:  70%|███████   | 14/20 [02:39<01:02, 10.44s/it]
Task 5, Epoch 15/20 => Loss 0.238, Train_accy 72.26:  70%|███████   | 14/20 [02:48<01:02, 10.44s/it]
Task 5, Epoch 15/20 => Loss 0.238, Train_accy 72.26:  75%|███████▌  | 15/20 [02:48<00:50, 10.03s/it]
Task 5, Epoch 16/20 => Loss 0.251, Train_accy 72.50, Test_accy 85.28:  75%|███████▌  | 15/20 [03:08<00:50, 10.03s/it]
Task 5, Epoch 16/20 => Loss 0.251, Train_accy 72.50, Test_accy 85.28:  80%|████████  | 16/20 [03:08<00:52, 13.03s/it]
Task 5, Epoch 17/20 => Loss 0.247, Train_accy 73.52:  80%|████████  | 16/20 [03:17<00:52, 13.03s/it]                 
Task 5, Epoch 17/20 => Loss 0.247, Train_accy 73.52:  85%|████████▌ | 17/20 [03:17<00:35, 11.86s/it]
Task 5, Epoch 18/20 => Loss 0.255, Train_accy 72.36:  85%|████████▌ | 17/20 [03:27<00:35, 11.86s/it]
Task 5, Epoch 18/20 => Loss 0.255, Train_accy 72.36:  90%|█████████ | 18/20 [03:27<00:22, 11.03s/it]
Task 5, Epoch 19/20 => Loss 0.249, Train_accy 72.44:  90%|█████████ | 18/20 [03:36<00:22, 11.03s/it]
Task 5, Epoch 19/20 => Loss 0.249, Train_accy 72.44:  95%|█████████▌| 19/20 [03:36<00:10, 10.45s/it]
Task 5, Epoch 20/20 => Loss 0.248, Train_accy 73.34:  95%|█████████▌| 19/20 [03:45<00:10, 10.45s/it]
Task 5, Epoch 20/20 => Loss 0.248, Train_accy 73.34: 100%|██████████| 20/20 [03:45<00:00, 10.05s/it]
Task 5, Epoch 20/20 => Loss 0.248, Train_accy 73.34: 100%|██████████| 20/20 [03:45<00:00, 11.27s/it]
2025-11-10 20:42:49,627 [sdfourier.py] => Task 5, Epoch 20/20 => Loss 0.248, Train_accy 73.34
2025-11-10 20:42:49,630 [trainer.py] => All params: 186044028
2025-11-10 20:42:49,631 [trainer.py] => Trainable params: 74940
2025-11-10 20:43:00,483 [trainer.py] => No NME accuracy.
2025-11-10 20:43:00,483 [trainer.py] => CNN: {'total': np.float64(85.37), '00-09': np.float64(84.7), '10-19': np.float64(83.7), '20-29': np.float64(86.0), '30-39': np.float64(85.2), '40-49': np.float64(83.0), '50-59': np.float64(89.6), 'old': np.float64(85.37), 'new': np.float64(nan)}
2025-11-10 20:43:00,483 [trainer.py] => CNN top1 curve: [np.float64(96.3), np.float64(92.5), np.float64(89.53), np.float64(87.8), np.float64(86.08), np.float64(85.37)]
2025-11-10 20:43:00,483 [trainer.py] => CNN top5 curve: [np.float64(99.8), np.float64(99.3), np.float64(99.0), np.float64(98.58), np.float64(97.98), np.float64(97.72)]

Average Accuracy (CNN): 89.59666666666668
2025-11-10 20:43:00,483 [trainer.py] => Average Accuracy (CNN): 89.59666666666668 

task 6
2025-11-10 20:43:00,484 [sdfourier.py] => Learning on 60-70

总共重置了 12 个模块的qkv层权重

  0%|          | 0/20 [00:00<?, ?it/s]
Task 6, Epoch 1/20 => Loss 0.853, Train_accy 47.46, Test_accy 83.83:   0%|          | 0/20 [00:21<?, ?it/s]
Task 6, Epoch 1/20 => Loss 0.853, Train_accy 47.46, Test_accy 83.83:   5%|▌         | 1/20 [00:21<06:51, 21.68s/it]
Task 6, Epoch 2/20 => Loss 0.552, Train_accy 68.98:   5%|▌         | 1/20 [00:30<06:51, 21.68s/it]                 
Task 6, Epoch 2/20 => Loss 0.552, Train_accy 68.98:  10%|█         | 2/20 [00:30<04:16, 14.27s/it]
Task 6, Epoch 3/20 => Loss 0.477, Train_accy 66.56:  10%|█         | 2/20 [00:39<04:16, 14.27s/it]
Task 6, Epoch 3/20 => Loss 0.477, Train_accy 66.56:  15%|█▌        | 3/20 [00:39<03:22, 11.91s/it]
Task 6, Epoch 4/20 => Loss 0.460, Train_accy 67.24:  15%|█▌        | 3/20 [00:48<03:22, 11.91s/it]
Task 6, Epoch 4/20 => Loss 0.460, Train_accy 67.24:  20%|██        | 4/20 [00:48<02:52, 10.81s/it]
Task 6, Epoch 5/20 => Loss 0.466, Train_accy 67.90:  20%|██        | 4/20 [00:58<02:52, 10.81s/it]
Task 6, Epoch 5/20 => Loss 0.466, Train_accy 67.90:  25%|██▌       | 5/20 [00:58<02:32, 10.19s/it]
Task 6, Epoch 6/20 => Loss 0.451, Train_accy 67.60, Test_accy 84.07:  25%|██▌       | 5/20 [01:19<02:32, 10.19s/it]
Task 6, Epoch 6/20 => Loss 0.451, Train_accy 67.60, Test_accy 84.07:  30%|███       | 6/20 [01:19<03:17, 14.10s/it]
Task 6, Epoch 7/20 => Loss 0.405, Train_accy 68.54:  30%|███       | 6/20 [01:28<03:17, 14.10s/it]                 
Task 6, Epoch 7/20 => Loss 0.405, Train_accy 68.54:  35%|███▌      | 7/20 [01:28<02:42, 12.46s/it]
Task 6, Epoch 8/20 => Loss 0.416, Train_accy 68.34:  35%|███▌      | 7/20 [01:37<02:42, 12.46s/it]
Task 6, Epoch 8/20 => Loss 0.416, Train_accy 68.34:  40%|████      | 8/20 [01:37<02:16, 11.39s/it]
Task 6, Epoch 9/20 => Loss 0.389, Train_accy 68.44:  40%|████      | 8/20 [01:47<02:16, 11.39s/it]
Task 6, Epoch 9/20 => Loss 0.389, Train_accy 68.44:  45%|████▌     | 9/20 [01:47<01:57, 10.67s/it]
Task 6, Epoch 10/20 => Loss 0.381, Train_accy 66.96:  45%|████▌     | 9/20 [01:56<01:57, 10.67s/it]
Task 6, Epoch 10/20 => Loss 0.381, Train_accy 66.96:  50%|█████     | 10/20 [01:56<01:41, 10.18s/it]
Task 6, Epoch 11/20 => Loss 0.370, Train_accy 68.72, Test_accy 84.41:  50%|█████     | 10/20 [02:17<01:41, 10.18s/it]
Task 6, Epoch 11/20 => Loss 0.370, Train_accy 68.72, Test_accy 84.41:  55%|█████▌    | 11/20 [02:17<02:03, 13.70s/it]
Task 6, Epoch 12/20 => Loss 0.363, Train_accy 66.92:  55%|█████▌    | 11/20 [02:26<02:03, 13.70s/it]                 
Task 6, Epoch 12/20 => Loss 0.363, Train_accy 66.92:  60%|██████    | 12/20 [02:26<01:38, 12.29s/it]
Task 6, Epoch 13/20 => Loss 0.357, Train_accy 67.50:  60%|██████    | 12/20 [02:35<01:38, 12.29s/it]
Task 6, Epoch 13/20 => Loss 0.357, Train_accy 67.50:  65%|██████▌   | 13/20 [02:35<01:19, 11.33s/it]
Task 6, Epoch 14/20 => Loss 0.379, Train_accy 67.92:  65%|██████▌   | 13/20 [02:45<01:19, 11.33s/it]
Task 6, Epoch 14/20 => Loss 0.379, Train_accy 67.92:  70%|███████   | 14/20 [02:45<01:03, 10.65s/it]
Task 6, Epoch 15/20 => Loss 0.349, Train_accy 67.26:  70%|███████   | 14/20 [02:54<01:03, 10.65s/it]
Task 6, Epoch 15/20 => Loss 0.349, Train_accy 67.26:  75%|███████▌  | 15/20 [02:54<00:50, 10.17s/it]
Task 6, Epoch 16/20 => Loss 0.348, Train_accy 67.18, Test_accy 84.46:  75%|███████▌  | 15/20 [03:15<00:50, 10.17s/it]
Task 6, Epoch 16/20 => Loss 0.348, Train_accy 67.18, Test_accy 84.46:  80%|████████  | 16/20 [03:15<00:54, 13.63s/it]
Task 6, Epoch 17/20 => Loss 0.350, Train_accy 67.62:  80%|████████  | 16/20 [03:24<00:54, 13.63s/it]                 
Task 6, Epoch 17/20 => Loss 0.350, Train_accy 67.62:  85%|████████▌ | 17/20 [03:24<00:36, 12.28s/it]
Task 6, Epoch 18/20 => Loss 0.338, Train_accy 67.72:  85%|████████▌ | 17/20 [03:34<00:36, 12.28s/it]
Task 6, Epoch 18/20 => Loss 0.338, Train_accy 67.72:  90%|█████████ | 18/20 [03:34<00:22, 11.32s/it]
Task 6, Epoch 19/20 => Loss 0.327, Train_accy 67.74:  90%|█████████ | 18/20 [03:43<00:22, 11.32s/it]
Task 6, Epoch 19/20 => Loss 0.327, Train_accy 67.74:  95%|█████████▌| 19/20 [03:43<00:10, 10.66s/it]
Task 6, Epoch 20/20 => Loss 0.343, Train_accy 66.52:  95%|█████████▌| 19/20 [03:52<00:10, 10.66s/it]
Task 6, Epoch 20/20 => Loss 0.343, Train_accy 66.52: 100%|██████████| 20/20 [03:52<00:00, 10.19s/it]
Task 6, Epoch 20/20 => Loss 0.343, Train_accy 66.52: 100%|██████████| 20/20 [03:52<00:00, 11.61s/it]
2025-11-10 20:46:56,317 [sdfourier.py] => Task 6, Epoch 20/20 => Loss 0.343, Train_accy 66.52
2025-11-10 20:46:56,320 [trainer.py] => All params: 186109318
2025-11-10 20:46:56,321 [trainer.py] => Trainable params: 82630
2025-11-10 20:47:08,890 [trainer.py] => No NME accuracy.
2025-11-10 20:47:08,891 [trainer.py] => CNN: {'total': np.float64(84.5), '00-09': np.float64(84.6), '10-19': np.float64(82.1), '20-29': np.float64(85.3), '30-39': np.float64(82.9), '40-49': np.float64(82.2), '50-59': np.float64(88.8), '60-69': np.float64(85.6), 'old': np.float64(84.5), 'new': np.float64(nan)}
2025-11-10 20:47:08,891 [trainer.py] => CNN top1 curve: [np.float64(96.3), np.float64(92.5), np.float64(89.53), np.float64(87.8), np.float64(86.08), np.float64(85.37), np.float64(84.5)]
2025-11-10 20:47:08,891 [trainer.py] => CNN top5 curve: [np.float64(99.8), np.float64(99.3), np.float64(99.0), np.float64(98.58), np.float64(97.98), np.float64(97.72), np.float64(97.41)]

Average Accuracy (CNN): 88.86857142857143
2025-11-10 20:47:08,891 [trainer.py] => Average Accuracy (CNN): 88.86857142857143 

task 7
2025-11-10 20:47:08,892 [sdfourier.py] => Learning on 70-80

总共重置了 12 个模块的qkv层权重

  0%|          | 0/20 [00:00<?, ?it/s]
Task 7, Epoch 1/20 => Loss 0.714, Train_accy 39.72, Test_accy 82.30:   0%|          | 0/20 [00:23<?, ?it/s]
Task 7, Epoch 1/20 => Loss 0.714, Train_accy 39.72, Test_accy 82.30:   5%|▌         | 1/20 [00:23<07:24, 23.41s/it]
Task 7, Epoch 2/20 => Loss 0.368, Train_accy 65.58:   5%|▌         | 1/20 [00:32<07:24, 23.41s/it]                 
Task 7, Epoch 2/20 => Loss 0.368, Train_accy 65.58:  10%|█         | 2/20 [00:32<04:31, 15.09s/it]
Task 7, Epoch 3/20 => Loss 0.313, Train_accy 64.60:  10%|█         | 2/20 [00:41<04:31, 15.09s/it]
Task 7, Epoch 3/20 => Loss 0.313, Train_accy 64.60:  15%|█▌        | 3/20 [00:41<03:30, 12.37s/it]
Task 7, Epoch 4/20 => Loss 0.282, Train_accy 64.44:  15%|█▌        | 3/20 [00:50<03:30, 12.37s/it]
Task 7, Epoch 4/20 => Loss 0.282, Train_accy 64.44:  20%|██        | 4/20 [00:50<02:57, 11.09s/it]
Task 7, Epoch 5/20 => Loss 0.269, Train_accy 65.60:  20%|██        | 4/20 [01:00<02:57, 11.09s/it]
Task 7, Epoch 5/20 => Loss 0.269, Train_accy 65.60:  25%|██▌       | 5/20 [01:00<02:35, 10.37s/it]
Task 7, Epoch 6/20 => Loss 0.279, Train_accy 64.82, Test_accy 83.12:  25%|██▌       | 5/20 [01:23<02:35, 10.37s/it]
Task 7, Epoch 6/20 => Loss 0.279, Train_accy 64.82, Test_accy 83.12:  30%|███       | 6/20 [01:23<03:27, 14.83s/it]
Task 7, Epoch 7/20 => Loss 0.278, Train_accy 65.30:  30%|███       | 6/20 [01:32<03:27, 14.83s/it]                 
Task 7, Epoch 7/20 => Loss 0.278, Train_accy 65.30:  35%|███▌      | 7/20 [01:32<02:48, 12.95s/it]
Task 7, Epoch 8/20 => Loss 0.283, Train_accy 65.76:  35%|███▌      | 7/20 [01:41<02:48, 12.95s/it]
Task 7, Epoch 8/20 => Loss 0.283, Train_accy 65.76:  40%|████      | 8/20 [01:41<02:20, 11.73s/it]
Task 7, Epoch 9/20 => Loss 0.238, Train_accy 65.04:  40%|████      | 8/20 [01:50<02:20, 11.73s/it]
Task 7, Epoch 9/20 => Loss 0.238, Train_accy 65.04:  45%|████▌     | 9/20 [01:50<02:00, 10.91s/it]
Task 7, Epoch 10/20 => Loss 0.240, Train_accy 65.36:  45%|████▌     | 9/20 [01:59<02:00, 10.91s/it]
Task 7, Epoch 10/20 => Loss 0.240, Train_accy 65.36:  50%|█████     | 10/20 [01:59<01:43, 10.36s/it]
Task 7, Epoch 11/20 => Loss 0.236, Train_accy 65.18, Test_accy 83.14:  50%|█████     | 10/20 [02:23<01:43, 10.36s/it]
Task 7, Epoch 11/20 => Loss 0.236, Train_accy 65.18, Test_accy 83.14:  55%|█████▌    | 11/20 [02:23<02:09, 14.37s/it]
Task 7, Epoch 12/20 => Loss 0.244, Train_accy 64.44:  55%|█████▌    | 11/20 [02:32<02:09, 14.37s/it]                 
Task 7, Epoch 12/20 => Loss 0.244, Train_accy 64.44:  60%|██████    | 12/20 [02:32<01:42, 12.76s/it]
Task 7, Epoch 13/20 => Loss 0.238, Train_accy 64.72:  60%|██████    | 12/20 [02:41<01:42, 12.76s/it]
Task 7, Epoch 13/20 => Loss 0.238, Train_accy 64.72:  65%|██████▌   | 13/20 [02:41<01:21, 11.65s/it]
Task 7, Epoch 14/20 => Loss 0.225, Train_accy 65.30:  65%|██████▌   | 13/20 [02:50<01:21, 11.65s/it]
Task 7, Epoch 14/20 => Loss 0.225, Train_accy 65.30:  70%|███████   | 14/20 [02:50<01:05, 10.92s/it]
Task 7, Epoch 15/20 => Loss 0.229, Train_accy 66.44:  70%|███████   | 14/20 [03:00<01:05, 10.92s/it]
Task 7, Epoch 15/20 => Loss 0.229, Train_accy 66.44:  75%|███████▌  | 15/20 [03:00<00:52, 10.40s/it]
Task 7, Epoch 16/20 => Loss 0.228, Train_accy 65.12, Test_accy 83.30:  75%|███████▌  | 15/20 [03:23<00:52, 10.40s/it]
Task 7, Epoch 16/20 => Loss 0.228, Train_accy 65.12, Test_accy 83.30:  80%|████████  | 16/20 [03:23<00:57, 14.33s/it]
Task 7, Epoch 17/20 => Loss 0.202, Train_accy 66.26:  80%|████████  | 16/20 [03:32<00:57, 14.33s/it]                 
Task 7, Epoch 17/20 => Loss 0.202, Train_accy 66.26:  85%|████████▌ | 17/20 [03:32<00:38, 12.77s/it]
Task 7, Epoch 18/20 => Loss 0.197, Train_accy 65.74:  85%|████████▌ | 17/20 [03:41<00:38, 12.77s/it]
Task 7, Epoch 18/20 => Loss 0.197, Train_accy 65.74:  90%|█████████ | 18/20 [03:41<00:23, 11.68s/it]
Task 7, Epoch 19/20 => Loss 0.212, Train_accy 64.18:  90%|█████████ | 18/20 [03:50<00:23, 11.68s/it]
Task 7, Epoch 19/20 => Loss 0.212, Train_accy 64.18:  95%|█████████▌| 19/20 [03:50<00:10, 10.92s/it]
Task 7, Epoch 20/20 => Loss 0.232, Train_accy 64.36:  95%|█████████▌| 19/20 [03:59<00:10, 10.92s/it]
Task 7, Epoch 20/20 => Loss 0.232, Train_accy 64.36: 100%|██████████| 20/20 [03:59<00:00, 10.37s/it]
Task 7, Epoch 20/20 => Loss 0.232, Train_accy 64.36: 100%|██████████| 20/20 [03:59<00:00, 12.00s/it]
2025-11-10 20:51:13,529 [sdfourier.py] => Task 7, Epoch 20/20 => Loss 0.232, Train_accy 64.36
2025-11-10 20:51:13,533 [trainer.py] => All params: 186179408
2025-11-10 20:51:13,534 [trainer.py] => Trainable params: 90320
2025-11-10 20:51:27,884 [trainer.py] => No NME accuracy.
2025-11-10 20:51:27,884 [trainer.py] => CNN: {'total': np.float64(83.3), '00-09': np.float64(82.2), '10-19': np.float64(81.7), '20-29': np.float64(84.8), '30-39': np.float64(81.8), '40-49': np.float64(79.9), '50-59': np.float64(88.4), '60-69': np.float64(85.4), '70-79': np.float64(82.2), 'old': np.float64(83.3), 'new': np.float64(nan)}
2025-11-10 20:51:27,884 [trainer.py] => CNN top1 curve: [np.float64(96.3), np.float64(92.5), np.float64(89.53), np.float64(87.8), np.float64(86.08), np.float64(85.37), np.float64(84.5), np.float64(83.3)]
2025-11-10 20:51:27,884 [trainer.py] => CNN top5 curve: [np.float64(99.8), np.float64(99.3), np.float64(99.0), np.float64(98.58), np.float64(97.98), np.float64(97.72), np.float64(97.41), np.float64(97.09)]

Average Accuracy (CNN): 88.1725
2025-11-10 20:51:27,884 [trainer.py] => Average Accuracy (CNN): 88.1725 

task 8
2025-11-10 20:51:27,885 [sdfourier.py] => Learning on 80-90

总共重置了 12 个模块的qkv层权重

  0%|          | 0/20 [00:00<?, ?it/s]
Task 8, Epoch 1/20 => Loss 0.816, Train_accy 49.28, Test_accy 80.38:   0%|          | 0/20 [00:25<?, ?it/s]
Task 8, Epoch 1/20 => Loss 0.816, Train_accy 49.28, Test_accy 80.38:   5%|▌         | 1/20 [00:25<07:58, 25.20s/it]
Task 8, Epoch 2/20 => Loss 0.406, Train_accy 74.72:   5%|▌         | 1/20 [00:34<07:58, 25.20s/it]                 
Task 8, Epoch 2/20 => Loss 0.406, Train_accy 74.72:  10%|█         | 2/20 [00:34<04:43, 15.73s/it]
Task 8, Epoch 3/20 => Loss 0.341, Train_accy 71.90:  10%|█         | 2/20 [00:43<04:43, 15.73s/it]
Task 8, Epoch 3/20 => Loss 0.341, Train_accy 71.90:  15%|█▌        | 3/20 [00:43<03:35, 12.70s/it]
Task 8, Epoch 4/20 => Loss 0.325, Train_accy 70.78:  15%|█▌        | 3/20 [00:52<03:35, 12.70s/it]
Task 8, Epoch 4/20 => Loss 0.325, Train_accy 70.78:  20%|██        | 4/20 [00:52<03:00, 11.28s/it]
Task 8, Epoch 5/20 => Loss 0.309, Train_accy 72.22:  20%|██        | 4/20 [01:01<03:00, 11.28s/it]
Task 8, Epoch 5/20 => Loss 0.309, Train_accy 72.22:  25%|██▌       | 5/20 [01:01<02:37, 10.49s/it]
Task 8, Epoch 6/20 => Loss 0.282, Train_accy 72.96, Test_accy 81.83:  25%|██▌       | 5/20 [01:26<02:37, 10.49s/it]
Task 8, Epoch 6/20 => Loss 0.282, Train_accy 72.96, Test_accy 81.83:  30%|███       | 6/20 [01:26<03:36, 15.48s/it]
Task 8, Epoch 7/20 => Loss 0.278, Train_accy 71.58:  30%|███       | 6/20 [01:35<03:36, 15.48s/it]                 
Task 8, Epoch 7/20 => Loss 0.278, Train_accy 71.58:  35%|███▌      | 7/20 [01:35<02:54, 13.39s/it]
Task 8, Epoch 8/20 => Loss 0.253, Train_accy 72.88:  35%|███▌      | 7/20 [01:44<02:54, 13.39s/it]
Task 8, Epoch 8/20 => Loss 0.253, Train_accy 72.88:  40%|████      | 8/20 [01:44<02:24, 12.03s/it]
Task 8, Epoch 9/20 => Loss 0.254, Train_accy 72.94:  40%|████      | 8/20 [01:54<02:24, 12.03s/it]
Task 8, Epoch 9/20 => Loss 0.254, Train_accy 72.94:  45%|████▌     | 9/20 [01:54<02:02, 11.13s/it]
Task 8, Epoch 10/20 => Loss 0.259, Train_accy 71.92:  45%|████▌     | 9/20 [02:03<02:02, 11.13s/it]
Task 8, Epoch 10/20 => Loss 0.259, Train_accy 71.92:  50%|█████     | 10/20 [02:03<01:45, 10.52s/it]
Task 8, Epoch 11/20 => Loss 0.235, Train_accy 71.60, Test_accy 82.03:  50%|█████     | 10/20 [02:28<01:45, 10.52s/it]
Task 8, Epoch 11/20 => Loss 0.235, Train_accy 71.60, Test_accy 82.03:  55%|█████▌    | 11/20 [02:28<02:15, 15.03s/it]
Task 8, Epoch 12/20 => Loss 0.242, Train_accy 72.08:  55%|█████▌    | 11/20 [02:37<02:15, 15.03s/it]                 
Task 8, Epoch 12/20 => Loss 0.242, Train_accy 72.08:  60%|██████    | 12/20 [02:37<01:45, 13.24s/it]
Task 8, Epoch 13/20 => Loss 0.228, Train_accy 72.74:  60%|██████    | 12/20 [02:46<01:45, 13.24s/it]
Task 8, Epoch 13/20 => Loss 0.228, Train_accy 72.74:  65%|██████▌   | 13/20 [02:46<01:23, 11.99s/it]
Task 8, Epoch 14/20 => Loss 0.216, Train_accy 72.12:  65%|██████▌   | 13/20 [02:55<01:23, 11.99s/it]
Task 8, Epoch 14/20 => Loss 0.216, Train_accy 72.12:  70%|███████   | 14/20 [02:55<01:06, 11.13s/it]
Task 8, Epoch 15/20 => Loss 0.232, Train_accy 70.92:  70%|███████   | 14/20 [03:05<01:06, 11.13s/it]
Task 8, Epoch 15/20 => Loss 0.232, Train_accy 70.92:  75%|███████▌  | 15/20 [03:05<00:52, 10.52s/it]
Task 8, Epoch 16/20 => Loss 0.202, Train_accy 71.88, Test_accy 81.82:  75%|███████▌  | 15/20 [03:30<00:52, 10.52s/it]
Task 8, Epoch 16/20 => Loss 0.202, Train_accy 71.88, Test_accy 81.82:  80%|████████  | 16/20 [03:30<00:59, 14.94s/it]
Task 8, Epoch 17/20 => Loss 0.226, Train_accy 71.46:  80%|████████  | 16/20 [03:39<00:59, 14.94s/it]                 
Task 8, Epoch 17/20 => Loss 0.226, Train_accy 71.46:  85%|████████▌ | 17/20 [03:39<00:39, 13.19s/it]
Task 8, Epoch 18/20 => Loss 0.230, Train_accy 71.60:  85%|████████▌ | 17/20 [03:48<00:39, 13.19s/it]
Task 8, Epoch 18/20 => Loss 0.230, Train_accy 71.60:  90%|█████████ | 18/20 [03:48<00:23, 11.96s/it]
Task 8, Epoch 19/20 => Loss 0.222, Train_accy 72.26:  90%|█████████ | 18/20 [03:57<00:23, 11.96s/it]
Task 8, Epoch 19/20 => Loss 0.222, Train_accy 72.26:  95%|█████████▌| 19/20 [03:57<00:11, 11.10s/it]
Task 8, Epoch 20/20 => Loss 0.208, Train_accy 71.70:  95%|█████████▌| 19/20 [04:06<00:11, 11.10s/it]
Task 8, Epoch 20/20 => Loss 0.208, Train_accy 71.70: 100%|██████████| 20/20 [04:06<00:00, 10.50s/it]
Task 8, Epoch 20/20 => Loss 0.208, Train_accy 71.70: 100%|██████████| 20/20 [04:06<00:00, 12.33s/it]
2025-11-10 20:55:40,294 [sdfourier.py] => Task 8, Epoch 20/20 => Loss 0.208, Train_accy 71.70
2025-11-10 20:55:40,297 [trainer.py] => All params: 186254298
2025-11-10 20:55:40,299 [trainer.py] => Trainable params: 98010
2025-11-10 20:55:56,374 [trainer.py] => No NME accuracy.
2025-11-10 20:55:56,374 [trainer.py] => CNN: {'total': np.float64(81.92), '00-09': np.float64(82.0), '10-19': np.float64(81.0), '20-29': np.float64(84.3), '30-39': np.float64(80.6), '40-49': np.float64(77.9), '50-59': np.float64(87.9), '60-69': np.float64(82.6), '70-79': np.float64(80.8), '80-89': np.float64(80.2), 'old': np.float64(81.92), 'new': np.float64(nan)}
2025-11-10 20:55:56,374 [trainer.py] => CNN top1 curve: [np.float64(96.3), np.float64(92.5), np.float64(89.53), np.float64(87.8), np.float64(86.08), np.float64(85.37), np.float64(84.5), np.float64(83.3), np.float64(81.92)]
2025-11-10 20:55:56,375 [trainer.py] => CNN top5 curve: [np.float64(99.8), np.float64(99.3), np.float64(99.0), np.float64(98.58), np.float64(97.98), np.float64(97.72), np.float64(97.41), np.float64(97.09), np.float64(96.8)]

Average Accuracy (CNN): 87.47777777777777
2025-11-10 20:55:56,375 [trainer.py] => Average Accuracy (CNN): 87.47777777777777 

task 9
2025-11-10 20:55:56,376 [sdfourier.py] => Learning on 90-100

总共重置了 12 个模块的qkv层权重

  0%|          | 0/20 [00:00<?, ?it/s]
Task 9, Epoch 1/20 => Loss 0.741, Train_accy 49.54, Test_accy 79.79:   0%|          | 0/20 [00:26<?, ?it/s]
Task 9, Epoch 1/20 => Loss 0.741, Train_accy 49.54, Test_accy 79.79:   5%|▌         | 1/20 [00:26<08:31, 26.91s/it]
Task 9, Epoch 2/20 => Loss 0.423, Train_accy 72.50:   5%|▌         | 1/20 [00:35<08:31, 26.91s/it]                 
Task 9, Epoch 2/20 => Loss 0.423, Train_accy 72.50:  10%|█         | 2/20 [00:35<04:55, 16.42s/it]
Task 9, Epoch 3/20 => Loss 0.340, Train_accy 68.26:  10%|█         | 2/20 [00:45<04:55, 16.42s/it]
Task 9, Epoch 3/20 => Loss 0.340, Train_accy 68.26:  15%|█▌        | 3/20 [00:45<03:42, 13.09s/it]
Task 9, Epoch 4/20 => Loss 0.351, Train_accy 68.28:  15%|█▌        | 3/20 [00:54<03:42, 13.09s/it]
Task 9, Epoch 4/20 => Loss 0.351, Train_accy 68.28:  20%|██        | 4/20 [00:54<03:04, 11.52s/it]
Task 9, Epoch 5/20 => Loss 0.318, Train_accy 67.66:  20%|██        | 4/20 [01:03<03:04, 11.52s/it]
Task 9, Epoch 5/20 => Loss 0.318, Train_accy 67.66:  25%|██▌       | 5/20 [01:03<02:39, 10.64s/it]
Task 9, Epoch 6/20 => Loss 0.287, Train_accy 68.88, Test_accy 81.01:  25%|██▌       | 5/20 [01:30<02:39, 10.64s/it]
Task 9, Epoch 6/20 => Loss 0.287, Train_accy 68.88, Test_accy 81.01:  30%|███       | 6/20 [01:30<03:46, 16.18s/it]
Task 9, Epoch 7/20 => Loss 0.326, Train_accy 69.10:  30%|███       | 6/20 [01:39<03:46, 16.18s/it]                 
Task 9, Epoch 7/20 => Loss 0.326, Train_accy 69.10:  35%|███▌      | 7/20 [01:39<03:00, 13.87s/it]
Task 9, Epoch 8/20 => Loss 0.297, Train_accy 68.52:  35%|███▌      | 7/20 [01:48<03:00, 13.87s/it]
Task 9, Epoch 8/20 => Loss 0.297, Train_accy 68.52:  40%|████      | 8/20 [01:48<02:28, 12.34s/it]
Task 9, Epoch 9/20 => Loss 0.308, Train_accy 67.60:  40%|████      | 8/20 [01:57<02:28, 12.34s/it]
Task 9, Epoch 9/20 => Loss 0.308, Train_accy 67.60:  45%|████▌     | 9/20 [01:57<02:04, 11.33s/it]
Task 9, Epoch 10/20 => Loss 0.295, Train_accy 67.46:  45%|████▌     | 9/20 [02:06<02:04, 11.33s/it]
Task 9, Epoch 10/20 => Loss 0.295, Train_accy 67.46:  50%|█████     | 10/20 [02:06<01:46, 10.64s/it]
Task 9, Epoch 11/20 => Loss 0.271, Train_accy 68.24, Test_accy 81.17:  50%|█████     | 10/20 [02:33<01:46, 10.64s/it]
Task 9, Epoch 11/20 => Loss 0.271, Train_accy 68.24, Test_accy 81.17:  55%|█████▌    | 11/20 [02:33<02:20, 15.63s/it]
Task 9, Epoch 12/20 => Loss 0.260, Train_accy 68.48:  55%|█████▌    | 11/20 [02:42<02:20, 15.63s/it]                 
Task 9, Epoch 12/20 => Loss 0.260, Train_accy 68.48:  60%|██████    | 12/20 [02:42<01:49, 13.64s/it]
Task 9, Epoch 13/20 => Loss 0.247, Train_accy 68.26:  60%|██████    | 12/20 [02:51<01:49, 13.64s/it]
Task 9, Epoch 13/20 => Loss 0.247, Train_accy 68.26:  65%|██████▌   | 13/20 [02:51<01:25, 12.26s/it]
Task 9, Epoch 14/20 => Loss 0.263, Train_accy 68.32:  65%|██████▌   | 13/20 [03:00<01:25, 12.26s/it]
Task 9, Epoch 14/20 => Loss 0.263, Train_accy 68.32:  70%|███████   | 14/20 [03:00<01:07, 11.30s/it]
Task 9, Epoch 15/20 => Loss 0.280, Train_accy 67.66:  70%|███████   | 14/20 [03:09<01:07, 11.30s/it]
Task 9, Epoch 15/20 => Loss 0.280, Train_accy 67.66:  75%|███████▌  | 15/20 [03:09<00:53, 10.64s/it]
Task 9, Epoch 16/20 => Loss 0.281, Train_accy 66.40, Test_accy 81.15:  75%|███████▌  | 15/20 [03:36<00:53, 10.64s/it]
Task 9, Epoch 16/20 => Loss 0.281, Train_accy 66.40, Test_accy 81.15:  80%|████████  | 16/20 [03:36<01:02, 15.54s/it]
Task 9, Epoch 17/20 => Loss 0.242, Train_accy 68.20:  80%|████████  | 16/20 [03:45<01:02, 15.54s/it]                 
Task 9, Epoch 17/20 => Loss 0.242, Train_accy 68.20:  85%|████████▌ | 17/20 [03:45<00:40, 13.61s/it]
Task 9, Epoch 18/20 => Loss 0.248, Train_accy 67.62:  85%|████████▌ | 17/20 [03:55<00:40, 13.61s/it]
Task 9, Epoch 18/20 => Loss 0.248, Train_accy 67.62:  90%|█████████ | 18/20 [03:55<00:24, 12.25s/it]
Task 9, Epoch 19/20 => Loss 0.251, Train_accy 66.60:  90%|█████████ | 18/20 [04:04<00:24, 12.25s/it]
Task 9, Epoch 19/20 => Loss 0.251, Train_accy 66.60:  95%|█████████▌| 19/20 [04:04<00:11, 11.32s/it]
Task 9, Epoch 20/20 => Loss 0.258, Train_accy 66.84:  95%|█████████▌| 19/20 [04:13<00:11, 11.32s/it]
Task 9, Epoch 20/20 => Loss 0.258, Train_accy 66.84: 100%|██████████| 20/20 [04:13<00:00, 10.66s/it]
Task 9, Epoch 20/20 => Loss 0.258, Train_accy 66.84: 100%|██████████| 20/20 [04:13<00:00, 12.67s/it]
2025-11-10 21:00:16,625 [sdfourier.py] => Task 9, Epoch 20/20 => Loss 0.258, Train_accy 66.84
2025-11-10 21:00:16,628 [trainer.py] => All params: 186333988
2025-11-10 21:00:16,629 [trainer.py] => Trainable params: 105700
2025-11-10 21:00:34,474 [trainer.py] => No NME accuracy.
2025-11-10 21:00:34,474 [trainer.py] => CNN: {'total': np.float64(81.17), '00-09': np.float64(81.6), '10-19': np.float64(80.1), '20-29': np.float64(83.4), '30-39': np.float64(80.2), '40-49': np.float64(76.1), '50-59': np.float64(87.4), '60-69': np.float64(82.0), '70-79': np.float64(80.2), '80-89': np.float64(79.9), '90-99': np.float64(80.8), 'old': np.float64(81.17), 'new': np.float64(nan)}
2025-11-10 21:00:34,474 [trainer.py] => CNN top1 curve: [np.float64(96.3), np.float64(92.5), np.float64(89.53), np.float64(87.8), np.float64(86.08), np.float64(85.37), np.float64(84.5), np.float64(83.3), np.float64(81.92), np.float64(81.17)]
2025-11-10 21:00:34,474 [trainer.py] => CNN top5 curve: [np.float64(99.8), np.float64(99.3), np.float64(99.0), np.float64(98.58), np.float64(97.98), np.float64(97.72), np.float64(97.41), np.float64(97.09), np.float64(96.8), np.float64(96.38)]

Average Accuracy (CNN): 86.847
2025-11-10 21:00:34,474 [trainer.py] => Average Accuracy (CNN): 86.847 

Accuracy Matrix (CNN):
[[96.3 91.8 89.7 87.9 84.9 84.7 84.6 82.2 82.  81.6]
 [ 0.  93.2 89.  86.  85.5 83.7 82.1 81.7 81.  80.1]
 [ 0.   0.  89.9 87.8 87.3 86.  85.3 84.8 84.3 83.4]
 [ 0.   0.   0.  89.5 86.7 85.2 82.9 81.8 80.6 80.2]
 [ 0.   0.   0.   0.  86.  83.  82.2 79.9 77.9 76.1]
 [ 0.   0.   0.   0.   0.  89.6 88.8 88.4 87.9 87.4]
 [ 0.   0.   0.   0.   0.   0.  85.6 85.4 82.6 82. ]
 [ 0.   0.   0.   0.   0.   0.   0.  82.2 80.8 80.2]
 [ 0.   0.   0.   0.   0.   0.   0.   0.  80.2 79.9]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.  80.8]]
2025-11-10 21:00:34,475 [trainer.py] => Forgetting (CNN): 6.844444444444444